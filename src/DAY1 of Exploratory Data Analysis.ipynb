{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h2> <b> Exploratory Data Analysis(EDA) Using Python.</b> </h2>\n",
    "</center> \n",
    "\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis or (EDA) is understanding the data sets by summarizing their main characteristics often plotting them visually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is very important especially when we arrive at modeling the data in order to apply Machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting in EDA consists of Histograms, Box plot, Scatter plot and many more. It often takes much time to explore the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the process of EDA, we can ask to define the problem statement or definition on our data set which is very important.\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to perform Exploratory Data Analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one such question that everyone is keen on knowing the answer. Well, the answer is it depends on the data set that you are working. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no one method or common methods in order to perform EDA, whereas in this guide you can understand some common methods and plots that would be used in the EDA process.\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What data are we exploring today?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am a huge fan of cars, I got a very beautiful data-set of cars from Kaggle. The data-set can be downloaded from [here](https://www.kaggle.com/CooperUnion/cardataset). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give a piece of brief information about the data set this data contains more of 10, 000 rows and more than 10 columns which contains features of the car such as Engine Fuel Type, Engine Size, HP, Transmission Type, highway MPG, city MPG and many more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this guide, we will explore the data and make it ready for modeling. \n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h3>\n",
    "    <b>\n",
    "        Exploratory Data Analysis Process.\n",
    "    </b>\n",
    "</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1). Importing the required libraries for EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the libraries that are used in order to perform EDA (Exploratory data analysis) in this guide. The complete code can be found on my GitHub.\n",
    "[Link to the Source Code](url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Importing required libraries.\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2). Loading the data into the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data into the pandas data frame is certainly one of the most important steps in EDA, as we can see that the value from the data set is comma-separated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all we have to do is to just read the CSV into a data frame and pandas data frame does the job for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using google colab her a simple step to read your dataset, <br>\n",
    "In <b> Google Colab </b> at the left-hand side of the notebook, you will find a <b> “>” </b> (greater than symbol). \n",
    "\n",
    "<br> When you click that you will find a tab with three options, you just have to select Files.\n",
    "\n",
    "<br> Then you can easily upload your file with the help of the Upload option. No need to mount to the google drive or use any specific libraries just upload the data set and your job is done.\n",
    "\n",
    "<br> \n",
    "<b> One thing to remember in this step is that uploaded files will get deleted when this runtime is recycled.\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CovidData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNo</th>\n",
       "      <th>ObservationDate</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>01/22/2020</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>01/22/2020</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>01/22/2020</td>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>01/22/2020</td>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>01/22/2020</td>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SNo ObservationDate Province/State  Country/Region      Last Update  \\\n",
       "0    1      01/22/2020          Anhui  Mainland China  1/22/2020 17:00   \n",
       "1    2      01/22/2020        Beijing  Mainland China  1/22/2020 17:00   \n",
       "2    3      01/22/2020      Chongqing  Mainland China  1/22/2020 17:00   \n",
       "3    4      01/22/2020         Fujian  Mainland China  1/22/2020 17:00   \n",
       "4    5      01/22/2020          Gansu  Mainland China  1/22/2020 17:00   \n",
       "\n",
       "   Confirmed  Deaths  Recovered  \n",
       "0        1.0     0.0        0.0  \n",
       "1       14.0     0.0        0.0  \n",
       "2        6.0     0.0        0.0  \n",
       "3        1.0     0.0        0.0  \n",
       "4        0.0     0.0        0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"To display the top 5 rows\"\"\"\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNo</th>\n",
       "      <th>ObservationDate</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205946</th>\n",
       "      <td>205947</td>\n",
       "      <td>01/19/2021</td>\n",
       "      <td>Zaporizhia Oblast</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>2021-01-20 05:21:54</td>\n",
       "      <td>62492.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>39168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205947</th>\n",
       "      <td>205948</td>\n",
       "      <td>01/19/2021</td>\n",
       "      <td>Zeeland</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>2021-01-20 05:21:54</td>\n",
       "      <td>13031.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205948</th>\n",
       "      <td>205949</td>\n",
       "      <td>01/19/2021</td>\n",
       "      <td>Zhejiang</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2021-01-20 05:21:54</td>\n",
       "      <td>1316.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205949</th>\n",
       "      <td>205950</td>\n",
       "      <td>01/19/2021</td>\n",
       "      <td>Zhytomyr Oblast</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>2021-01-20 05:21:54</td>\n",
       "      <td>42758.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>37834.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205950</th>\n",
       "      <td>205951</td>\n",
       "      <td>01/19/2021</td>\n",
       "      <td>Zuid-Holland</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>2021-01-20 05:21:54</td>\n",
       "      <td>224398.0</td>\n",
       "      <td>3153.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SNo ObservationDate     Province/State  Country/Region  \\\n",
       "205946  205947      01/19/2021  Zaporizhia Oblast         Ukraine   \n",
       "205947  205948      01/19/2021            Zeeland     Netherlands   \n",
       "205948  205949      01/19/2021           Zhejiang  Mainland China   \n",
       "205949  205950      01/19/2021    Zhytomyr Oblast         Ukraine   \n",
       "205950  205951      01/19/2021       Zuid-Holland     Netherlands   \n",
       "\n",
       "                Last Update  Confirmed  Deaths  Recovered  \n",
       "205946  2021-01-20 05:21:54    62492.0   738.0    39168.0  \n",
       "205947  2021-01-20 05:21:54    13031.0   149.0        0.0  \n",
       "205948  2021-01-20 05:21:54     1316.0     1.0     1298.0  \n",
       "205949  2021-01-20 05:21:54    42758.0   707.0    37834.0  \n",
       "205950  2021-01-20 05:21:54   224398.0  3153.0        0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"To display the bottom 5 rows\"\"\"\n",
    "df.tail(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3). Checking the types of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check for the datatypes because sometimes the MSRP or the price of the car would be stored as a string or object, if in that case, we have to convert that string to the integer data only then we can plot the data via a graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, in this case, the data is already in integer format so nothing to worry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNo                  int64\n",
       "ObservationDate     object\n",
       "Province/State      object\n",
       "Country/Region      object\n",
       "Last Update         object\n",
       "Confirmed          float64\n",
       "Deaths             float64\n",
       "Recovered          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Checking the data type\"\"\"\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4). Dropping irrelevant columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is certainly needed in every EDA because sometimes there would be many columns that we never use in such cases dropping is the only solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the columns such as Engine Fuel Type, Market Category, Vehicle style, Popularity, Number of doors, Vehicle Size doesn't make any sense to me so I just dropped for this instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-17-06dbd36c4729>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-06dbd36c4729>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    df = df.drop([‘Engine Fuel Type’, ‘Market Category’, ‘Vehicle Style’, ‘Popularity’, ‘Number of Doors’, ‘Vehicle Size’], axis=1)\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "# Dropping irrelevant columns\n",
    "df = df.drop([‘Engine Fuel Type’, ‘Market Category’, ‘Vehicle Style’, ‘Popularity’, ‘Number of Doors’, ‘Vehicle Size’], axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Renaming the columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this instance, most of the column names are very confusing to read, so I just tweaked their column names. This is a good approach it improves the readability of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-19-66d0da2e1637>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-66d0da2e1637>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    df = df.rename(columns={“Engine HP”: “HP”, “Engine Cylinders”: “Cylinders”, “Transmission Type”: “Transmission”, “Driven_Wheels”: “Drive Mode”,”highway MPG”: “MPG-H”, “city mpg”: “MPG-C”, “MSRP”: “Price” })\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "# Renaming the column names\n",
    "df = df.rename(columns={“Engine HP”: “HP”, “Engine Cylinders”: “Cylinders”, “Transmission Type”: “Transmission”, “Driven_Wheels”: “Drive Mode”,”highway MPG”: “MPG-H”, “city mpg”: “MPG-C”, “MSRP”: “Price” })\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Dropping the duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is often a handy thing to do because a huge data set as in this case contains more than 10, 000 rows often have some duplicate data which might be disturbing, so here I remove all the duplicate value from the data-set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example prior to removing I had 11914 rows of data but after removing the duplicates 10925 data meaning that I had 989 of duplicate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-21-6325787e99ce>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-6325787e99ce>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print(“number of duplicate rows:\", duplicate_rows_df.shape)\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Total number of rows and columns\"\"\"\n",
    "df.shape\n",
    "(11914, 10)\n",
    "\n",
    "\"\"\"Rows containing duplicate data\"\"\"\n",
    "duplicate_rows_df = df[df.duplicated()]\n",
    "print(“number of duplicate rows:\", duplicate_rows_df.shape)\n",
    "number of duplicate rows:  (989, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us remove the duplicate data because it's ok to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNo                205951\n",
       "ObservationDate    205951\n",
       "Province/State     150574\n",
       "Country/Region     205951\n",
       "Last Update        205951\n",
       "Confirmed          205951\n",
       "Deaths             205951\n",
       "Recovered          205951\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used to count the number of rows before removing the data\n",
    "df.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
